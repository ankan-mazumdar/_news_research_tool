{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae222ed8",
   "metadata": {},
   "source": [
    "## Document Loaders In LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65dada0",
   "metadata": {},
   "source": [
    "#### TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "470ed0a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"The stock of NVIDIA Corp (NASDAQ:NVDA) experienced a daily loss of -3.56% and a 3-month gain of 32.35%. With an Earnings Per Share (EPS) (EPS) of $1.92, the question arises: is the stock significantly overvalued? This article aims to provide a detailed valuation analysis of NVIDIA, offering insights into its financial strength, profitability, growth, and more. We invite you to delve into this comprehensive analysis.\\n\\nCompany Overview\\nWarning! GuruFocus has detected 10 Warning Signs with NVDA. Click here to check it out.\\n\\nNVDA 30-Year Financial Data\\n\\nThe intrinsic value of NVDA\\n\\n\\nNVIDIA Corp (NASDAQ:NVDA) is a leading designer of discrete graphics processing units that enhance the experience on computing platforms. The firm's chips are widely used in various end markets, including PC gaming and data centers. In recent years, NVIDIA has broadened its focus from traditional PC graphics applications such as gaming to more complex and favorable opportunities, including artificial intelligence and autonomous driving, leveraging the high-performance capabilities of its products.\\n\\nCurrently, NVIDIA's stock price stands at $418.01, significantly higher than the GF Value of $310.28, indicating the stock might be overvalued. With a market cap of $1 trillion, the valuation seems steep. The following analysis aims to delve deeper into the company's value.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nUnderstanding the GF Value\\nThe GF Value is a unique measure of the intrinsic value of a stock, calculated based on historical trading multiples, a GuruFocus adjustment factor, and future business performance estimates. If the stock price is significantly above the GF Value Line, it is overvalued, and its future return is likely to be poor. Conversely, if it is significantly below the GF Value Line, its future return will likely be higher.\\n\\nAccording to GuruFocus Value calculation, NVIDIA (NASDAQ:NVDA) appears to be significantly overvalued. The stock's current price of $418.01 per share and the market cap of $1 trillion further strengthen this assumption.\\n\\nGiven that NVIDIA is significantly overvalued, the long-term return of its stock is likely to be much lower than its future business growth.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nLink: These companies may deliver higher future returns at reduced risk.\\n\\nFinancial Strength of NVIDIA\\nExamining the financial strength of a company is crucial before investing in its stock. Companies with poor financial strength pose a higher risk of permanent loss. NVIDIA's cash-to-debt ratio of 1.27 is worse than 58.04% of companies in the Semiconductors industry. However, NVIDIA's overall financial strength is 8 out of 10, indicating a strong financial position.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nProfitability and Growth\\nConsistent profitability over the long term reduces the risk for investors. NVIDIA, with its profitability ranking of 10 out of 10, has been profitable for the past 10 years. The company's operating margin of 17.37% ranks better than 76.5% of companies in the Semiconductors industry.\\n\\nHowever, growth is a crucial factor in a company's valuation. NVIDIA's growth ranks worse than 52.99% of companies in the Semiconductors industry, with its 3-year average revenue growth rate better than 87.88% of companies in the industry.\\n\\nROIC vs WACC\\nComparing a company's return on invested capital (ROIC) to its weighted average cost of capital (WACC) is an effective way to evaluate its profitability. Over the past 12 months, NVIDIA's ROIC was 20.32 while its WACC was 16.74, suggesting that the company is creating value for its shareholders.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nConclusion\\nIn conclusion, NVIDIA (NASDAQ:NVDA) appears to be significantly overvalued. Despite its strong financial condition and profitability, its growth ranks lower than 52.99% of companies in the Semiconductors industry. To learn more about NVIDIA stock, you can check out its 30-Year Financials here.\\n\\nTo find out the high quality companies that may deliver above-average returns, please check out GuruFocus High Quality Low Capex Screener.\\n\\nThis article first appeared on GuruFocus.\", metadata={'source': 'nvda_news_1.txt'})]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"nvda_news_1.txt\")\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca5844b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_community.document_loaders.text.TextLoader"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb95e130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nvda_news_1.txt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da25ff7",
   "metadata": {},
   "source": [
    "#### CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad67ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "220b3fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='movie_id: 101\\ntitle: K.G.F: Chapter 2\\nindustry: Bollywood\\nrelease_year: 2022\\nimdb_rating: 8.4\\nstudio: Hombale Films\\nlanguage_id: 3\\nbudget: 1\\nrevenue: 12.5\\nunit: Billions\\ncurrency: INR', metadata={'source': 'movies.csv', 'row': 0}),\n",
       " Document(page_content='movie_id: 102\\ntitle: Doctor Strange in the Multiverse of Madness\\nindustry: Hollywood\\nrelease_year: 2022\\nimdb_rating: 7\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 200\\nrevenue: 954.8\\nunit: Millions\\ncurrency: USD', metadata={'source': 'movies.csv', 'row': 1}),\n",
       " Document(page_content='movie_id: 103\\ntitle: Thor: The Dark World\\nindustry: Hollywood\\nrelease_year: 2013\\nimdb_rating: 6.8\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 165\\nrevenue: 644.8\\nunit: Millions\\ncurrency: USD', metadata={'source': 'movies.csv', 'row': 2}),\n",
       " Document(page_content='movie_id: 104\\ntitle: Thor: Ragnarok\\nindustry: Hollywood\\nrelease_year: 2017\\nimdb_rating: 7.9\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 180\\nrevenue: 854\\nunit: Millions\\ncurrency: USD', metadata={'source': 'movies.csv', 'row': 3}),\n",
       " Document(page_content='movie_id: 105\\ntitle: Thor: Love and Thunder\\nindustry: Hollywood\\nrelease_year: 2022\\nimdb_rating: 6.8\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 250\\nrevenue: 670\\nunit: Millions\\ncurrency: USD', metadata={'source': 'movies.csv', 'row': 4}),\n",
       " Document(page_content='movie_id: 106\\ntitle: Sholay\\nindustry: Bollywood\\nrelease_year: 1975\\nimdb_rating: 8.1\\nstudio: United Producers\\nlanguage_id: 1\\nbudget: Not Available\\nrevenue: Not Available\\nunit: Not Available\\ncurrency: Not Available', metadata={'source': 'movies.csv', 'row': 5}),\n",
       " Document(page_content='movie_id: 107\\ntitle: Dilwale Dulhania Le Jayenge\\nindustry: Bollywood\\nrelease_year: 1995\\nimdb_rating: 8\\nstudio: Yash Raj Films\\nlanguage_id: 1\\nbudget: 400\\nrevenue: 2000\\nunit: Millions\\ncurrency: INR', metadata={'source': 'movies.csv', 'row': 6}),\n",
       " Document(page_content='movie_id: 108\\ntitle: 3 Idiots\\nindustry: Bollywood\\nrelease_year: 2009\\nimdb_rating: 8.4\\nstudio: Vinod Chopra Films\\nlanguage_id: 1\\nbudget: 550\\nrevenue: 4000\\nunit: Millions\\ncurrency: INR', metadata={'source': 'movies.csv', 'row': 7}),\n",
       " Document(page_content='movie_id: 109\\ntitle: Kabhi Khushi Kabhie Gham\\nindustry: Bollywood\\nrelease_year: 2001\\nimdb_rating: 7.4\\nstudio: Dharma Productions\\nlanguage_id: 1\\nbudget: 390\\nrevenue: 1360\\nunit: Millions\\ncurrency: INR', metadata={'source': 'movies.csv', 'row': 8})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = CSVLoader(file_path=\"movies.csv\")\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e1b3b9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='movie_id: 101\\ntitle: K.G.F: Chapter 2\\nindustry: Bollywood\\nrelease_year: 2022\\nimdb_rating: 8.4\\nstudio: Hombale Films\\nlanguage_id: 3\\nbudget: 1\\nrevenue: 12.5\\nunit: Billions\\ncurrency: INR', metadata={'source': 'movies.csv', 'row': 0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e356cd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='movie_id: 101\\ntitle: K.G.F: Chapter 2\\nindustry: Bollywood\\nrelease_year: 2022\\nimdb_rating: 8.4\\nstudio: Hombale Films\\nlanguage_id: 3\\nbudget: 1\\nrevenue: 12.5\\nunit: Billions\\ncurrency: INR', metadata={'source': 'K.G.F: Chapter 2', 'row': 0}),\n",
       " Document(page_content='movie_id: 102\\ntitle: Doctor Strange in the Multiverse of Madness\\nindustry: Hollywood\\nrelease_year: 2022\\nimdb_rating: 7\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 200\\nrevenue: 954.8\\nunit: Millions\\ncurrency: USD', metadata={'source': 'Doctor Strange in the Multiverse of Madness', 'row': 1}),\n",
       " Document(page_content='movie_id: 103\\ntitle: Thor: The Dark World\\nindustry: Hollywood\\nrelease_year: 2013\\nimdb_rating: 6.8\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 165\\nrevenue: 644.8\\nunit: Millions\\ncurrency: USD', metadata={'source': 'Thor: The Dark World', 'row': 2}),\n",
       " Document(page_content='movie_id: 104\\ntitle: Thor: Ragnarok\\nindustry: Hollywood\\nrelease_year: 2017\\nimdb_rating: 7.9\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 180\\nrevenue: 854\\nunit: Millions\\ncurrency: USD', metadata={'source': 'Thor: Ragnarok', 'row': 3}),\n",
       " Document(page_content='movie_id: 105\\ntitle: Thor: Love and Thunder\\nindustry: Hollywood\\nrelease_year: 2022\\nimdb_rating: 6.8\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 250\\nrevenue: 670\\nunit: Millions\\ncurrency: USD', metadata={'source': 'Thor: Love and Thunder', 'row': 4}),\n",
       " Document(page_content='movie_id: 106\\ntitle: Sholay\\nindustry: Bollywood\\nrelease_year: 1975\\nimdb_rating: 8.1\\nstudio: United Producers\\nlanguage_id: 1\\nbudget: Not Available\\nrevenue: Not Available\\nunit: Not Available\\ncurrency: Not Available', metadata={'source': 'Sholay', 'row': 5}),\n",
       " Document(page_content='movie_id: 107\\ntitle: Dilwale Dulhania Le Jayenge\\nindustry: Bollywood\\nrelease_year: 1995\\nimdb_rating: 8\\nstudio: Yash Raj Films\\nlanguage_id: 1\\nbudget: 400\\nrevenue: 2000\\nunit: Millions\\ncurrency: INR', metadata={'source': 'Dilwale Dulhania Le Jayenge', 'row': 6}),\n",
       " Document(page_content='movie_id: 108\\ntitle: 3 Idiots\\nindustry: Bollywood\\nrelease_year: 2009\\nimdb_rating: 8.4\\nstudio: Vinod Chopra Films\\nlanguage_id: 1\\nbudget: 550\\nrevenue: 4000\\nunit: Millions\\ncurrency: INR', metadata={'source': '3 Idiots', 'row': 7}),\n",
       " Document(page_content='movie_id: 109\\ntitle: Kabhi Khushi Kabhie Gham\\nindustry: Bollywood\\nrelease_year: 2001\\nimdb_rating: 7.4\\nstudio: Dharma Productions\\nlanguage_id: 1\\nbudget: 390\\nrevenue: 1360\\nunit: Millions\\ncurrency: INR', metadata={'source': 'Kabhi Khushi Kabhie Gham', 'row': 8})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = CSVLoader(file_path=\"movies.csv\", source_column=\"title\")\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42d13fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movie_id: 101\\ntitle: K.G.F: Chapter 2\\nindustry: Bollywood\\nrelease_year: 2022\\nimdb_rating: 8.4\\nstudio: Hombale Films\\nlanguage_id: 3\\nbudget: 1\\nrevenue: 12.5\\nunit: Billions\\ncurrency: INR'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d8913df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'K.G.F: Chapter 2', 'row': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0163924",
   "metadata": {},
   "source": [
    "#### UnstructuredURLLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48644959",
   "metadata": {},
   "source": [
    "UnstructuredURLLoader of Langchain internally uses unstructured python library to load the content from url's\n",
    "\n",
    "https://unstructured-io.github.io/unstructured/introduction.html\n",
    "\n",
    "https://pypi.org/project/unstructured/#description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70f51f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.0.284 (from -r ../requirements.txt (line 1))\n",
      "  Obtaining dependency information for langchain==0.0.284 from https://files.pythonhosted.org/packages/e0/0f/ad9d8095ec147c1b33584b69f287e0e39abef1c2955d834802c3592b0c8d/langchain-0.0.284-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.0.284-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting python-dotenv==1.0.0 (from -r ../requirements.txt (line 2))\n",
      "  Obtaining dependency information for python-dotenv==1.0.0 from https://files.pythonhosted.org/packages/44/2f/62ea1c8b593f4e093cc1a7768f0d46112107e790c3e478532329e434f00b/python_dotenv-1.0.0-py3-none-any.whl.metadata\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting streamlit==1.22.0 (from -r ../requirements.txt (line 3))\n",
      "  Obtaining dependency information for streamlit==1.22.0 from https://files.pythonhosted.org/packages/b1/26/2add66d2e2febd6b05efd48ce02fc2d979d805b844143f2fa9fd7e867ade/streamlit-1.22.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading streamlit-1.22.0-py2.py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting unstructured==0.9.2 (from -r ../requirements.txt (line 4))\n",
      "  Obtaining dependency information for unstructured==0.9.2 from https://files.pythonhosted.org/packages/a7/98/5ccd2b4003c6a38303832c6170bee1c3821202771121abe7af81c2adbe05/unstructured-0.9.2-py3-none-any.whl.metadata\n",
      "  Downloading unstructured-0.9.2-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting tiktoken==0.4.0 (from -r ../requirements.txt (line 5))\n",
      "  Downloading tiktoken-0.4.0.tar.gz (25 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting faiss-cpu==1.7.4 (from -r ../requirements.txt (line 6))\n",
      "  Downloading faiss-cpu-1.7.4.tar.gz (57 kB)\n",
      "     ---------------------------------------- 0.0/57.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.4/57.4 kB 1.5 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting libmagic==1.0 (from -r ../requirements.txt (line 7))\n",
      "  Downloading libmagic-1.0.tar.gz (3.7 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting python-magic==0.4.27 (from -r ../requirements.txt (line 8))\n",
      "  Obtaining dependency information for python-magic==0.4.27 from https://files.pythonhosted.org/packages/6c/73/9f872cb81fc5c3bb48f7227872c28975f998f3e7c2b1c16e95e6432bbb90/python_magic-0.4.27-py2.py3-none-any.whl.metadata\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting python-magic-bin==0.4.14 (from -r ../requirements.txt (line 9))\n",
      "  Obtaining dependency information for python-magic-bin==0.4.14 from https://files.pythonhosted.org/packages/07/c2/094e3d62b906d952537196603a23aec4bcd7c6126bf80eb14e6f9f4be3a2/python_magic_bin-0.4.14-py2.py3-none-win_amd64.whl.metadata\n",
      "  Downloading python_magic_bin-0.4.14-py2.py3-none-win_amd64.whl.metadata (710 bytes)\n",
      "Collecting OpenAI==0.28.0 (from -r ../requirements.txt (line 10))\n",
      "  Obtaining dependency information for OpenAI==0.28.0 from https://files.pythonhosted.org/packages/ae/59/911d6e5f1d7514d79c527067643376cddcf4cb8d1728e599b3b03ab51c69/openai-0.28.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\python\\lib\\site-packages (from langchain==0.0.284->-r ../requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\python\\lib\\site-packages (from langchain==0.0.284->-r ../requirements.txt (line 1)) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\python\\lib\\site-packages (from langchain==0.0.284->-r ../requirements.txt (line 1)) (3.9.5)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.284->-r ../requirements.txt (line 1))\n",
      "  Obtaining dependency information for dataclasses-json<0.6.0,>=0.5.7 from https://files.pythonhosted.org/packages/97/5f/e7cc90f36152810cab08b6c9c1125e8bcb9d76f8b3018d101b5f877b386c/dataclasses_json-0.5.14-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.5.14-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.21 (from langchain==0.0.284->-r ../requirements.txt (line 1))\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.21 from https://files.pythonhosted.org/packages/97/cd/1c618f89d3fcbb375c99a3ea950bffba8a01862cc0f0ab5032dfb95e8d1e/langsmith-0.0.92-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\python\\lib\\site-packages (from langchain==0.0.284->-r ../requirements.txt (line 1)) (2.10.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\python\\lib\\site-packages (from langchain==0.0.284->-r ../requirements.txt (line 1)) (1.26.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\python\\lib\\site-packages (from langchain==0.0.284->-r ../requirements.txt (line 1)) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\python\\lib\\site-packages (from langchain==0.0.284->-r ../requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\python\\lib\\site-packages (from langchain==0.0.284->-r ../requirements.txt (line 1)) (8.2.3)\n",
      "Collecting altair<5,>=3.2.0 (from streamlit==1.22.0->-r ../requirements.txt (line 3))\n",
      "  Obtaining dependency information for altair<5,>=3.2.0 from https://files.pythonhosted.org/packages/18/62/47452306e84d4d2e67f9c559380aeb230f5e6ca84fafb428dd36b96a99ba/altair-4.2.2-py3-none-any.whl.metadata\n",
      "  Downloading altair-4.2.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: blinker>=1.0.0 in c:\\python\\lib\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (1.7.0)\n",
      "Requirement already satisfied: cachetools>=4.0 in c:\\python\\lib\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (5.3.2)\n",
      "Requirement already satisfied: click>=7.0 in c:\\python\\lib\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\python\\lib\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (6.8.0)\n",
      "Requirement already satisfied: packaging>=14.1 in c:\\users\\ankan mazumdar\\appdata\\roaming\\python\\python312\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=0.25 in c:\\python\\lib\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python\\lib\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (10.0.1)\n",
      "Collecting protobuf<4,>=3.12 (from streamlit==1.22.0->-r ../requirements.txt (line 3))\n",
      "  Obtaining dependency information for protobuf<4,>=3.12 from https://files.pythonhosted.org/packages/8d/14/619e24a4c70df2901e1f4dbc50a6291eb63a759172558df326347dce1f0d/protobuf-3.20.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Requirement already satisfied: pyarrow>=4.0 in c:\\python\\lib\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (14.0.1)\n",
      "Collecting pympler>=0.9 (from streamlit==1.22.0->-r ../requirements.txt (line 3))\n",
      "  Obtaining dependency information for pympler>=0.9 from https://files.pythonhosted.org/packages/2c/42/41e1469ed0b37b9c8532cb8074bea179f7d85ee7e82a59b5b6c289ed6045/Pympler-1.0.1-py3-none-any.whl.metadata\n",
      "  Downloading Pympler-1.0.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\ankan mazumdar\\appdata\\roaming\\python\\python312\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\python\\lib\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (13.6.0)\n",
      "Requirement already satisfied: toml in c:\\python\\lib\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in c:\\python\\lib\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (4.8.0)\n",
      "Requirement already satisfied: tzlocal>=1.1 in c:\\python\\lib\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (5.2)\n",
      "Requirement already satisfied: validators>=0.2 in c:\\python\\lib\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (0.22.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19 in c:\\python\\lib\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (3.1.40)\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in c:\\python\\lib\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (0.8.1b0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in c:\\users\\ankan mazumdar\\appdata\\roaming\\python\\python312\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (6.3.3)\n",
      "Requirement already satisfied: watchdog in c:\\python\\lib\\site-packages (from streamlit==1.22.0->-r ../requirements.txt (line 3)) (3.0.0)\n",
      "Collecting chardet (from unstructured==0.9.2->-r ../requirements.txt (line 4))\n",
      "  Obtaining dependency information for chardet from https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl.metadata\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured==0.9.2->-r ../requirements.txt (line 4))\n",
      "  Obtaining dependency information for filetype from https://files.pythonhosted.org/packages/18/79/1b8fa1bb3568781e84c9200f951c735f3f157429f44be0495da55894d620/filetype-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: lxml in c:\\python\\lib\\site-packages (from unstructured==0.9.2->-r ../requirements.txt (line 4)) (4.9.3)\n",
      "Collecting nltk (from unstructured==0.9.2->-r ../requirements.txt (line 4))\n",
      "  Obtaining dependency information for nltk from https://files.pythonhosted.org/packages/a6/0a/0d20d2c0f16be91b9fa32a77b76c60f9baf6eba419e5ef5deca17af9c582/nltk-3.8.1-py3-none-any.whl.metadata\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting tabulate (from unstructured==0.9.2->-r ../requirements.txt (line 4))\n",
      "  Obtaining dependency information for tabulate from https://files.pythonhosted.org/packages/40/44/4a5f08c96eb108af5cb50b41f76142f0afa346dfa99d5296fe7202a11854/tabulate-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken==0.4.0->-r ../requirements.txt (line 5))\n",
      "  Obtaining dependency information for regex>=2022.1.18 from https://files.pythonhosted.org/packages/8b/ee/05f14a99a81f1a897a9146f3f565efb116ad6412f875f52e895c02666825/regex-2024.5.15-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\python\\lib\\site-packages (from OpenAI==0.28.0->-r ../requirements.txt (line 10)) (4.66.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284->-r ../requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284->-r ../requirements.txt (line 1)) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284->-r ../requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284->-r ../requirements.txt (line 1)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.284->-r ../requirements.txt (line 1)) (1.9.4)\n",
      "Collecting entrypoints (from altair<5,>=3.2.0->streamlit==1.22.0->-r ../requirements.txt (line 3))\n",
      "  Obtaining dependency information for entrypoints from https://files.pythonhosted.org/packages/35/a8/365059bbcd4572cbc41de17fd5b682be5868b218c3c5479071865cab9078/entrypoints-0.4-py3-none-any.whl.metadata\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\python\\lib\\site-packages (from altair<5,>=3.2.0->streamlit==1.22.0->-r ../requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\python\\lib\\site-packages (from altair<5,>=3.2.0->streamlit==1.22.0->-r ../requirements.txt (line 3)) (4.19.2)\n",
      "Requirement already satisfied: toolz in c:\\python\\lib\\site-packages (from altair<5,>=3.2.0->streamlit==1.22.0->-r ../requirements.txt (line 3)) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ankan mazumdar\\appdata\\roaming\\python\\python312\\site-packages (from click>=7.0->streamlit==1.22.0->-r ../requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\python\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.284->-r ../requirements.txt (line 1)) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\python\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.284->-r ../requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\python\\lib\\site-packages (from gitpython!=3.1.19->streamlit==1.22.0->-r ../requirements.txt (line 3)) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\python\\lib\\site-packages (from importlib-metadata>=1.4->streamlit==1.22.0->-r ../requirements.txt (line 3)) (3.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python\\lib\\site-packages (from pandas<3,>=0.25->streamlit==1.22.0->-r ../requirements.txt (line 3)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python\\lib\\site-packages (from pandas<3,>=0.25->streamlit==1.22.0->-r ../requirements.txt (line 3)) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\python\\lib\\site-packages (from pydantic<3,>=1->langchain==0.0.284->-r ../requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\python\\lib\\site-packages (from pydantic<3,>=1->langchain==0.0.284->-r ../requirements.txt (line 1)) (2.18.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ankan mazumdar\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil->streamlit==1.22.0->-r ../requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\lib\\site-packages (from requests<3,>=2->langchain==0.0.284->-r ../requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\lib\\site-packages (from requests<3,>=2->langchain==0.0.284->-r ../requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\lib\\site-packages (from requests<3,>=2->langchain==0.0.284->-r ../requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\lib\\site-packages (from requests<3,>=2->langchain==0.0.284->-r ../requirements.txt (line 1)) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python\\lib\\site-packages (from rich>=10.11.0->streamlit==1.22.0->-r ../requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ankan mazumdar\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->streamlit==1.22.0->-r ../requirements.txt (line 3)) (2.16.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\python\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.284->-r ../requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: joblib in c:\\python\\lib\\site-packages (from nltk->unstructured==0.9.2->-r ../requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\python\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit==1.22.0->-r ../requirements.txt (line 3)) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python\\lib\\site-packages (from jinja2->altair<5,>=3.2.0->streamlit==1.22.0->-r ../requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\python\\lib\\site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.22.0->-r ../requirements.txt (line 3)) (2023.11.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\python\\lib\\site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.22.0->-r ../requirements.txt (line 3)) (0.31.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\python\\lib\\site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.22.0->-r ../requirements.txt (line 3)) (0.12.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\python\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->streamlit==1.22.0->-r ../requirements.txt (line 3)) (0.1.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\python\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.284->-r ../requirements.txt (line 1)) (1.0.0)\n",
      "Downloading langchain-0.0.284-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/1.7 MB 5.3 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.3/1.7 MB 3.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.4/1.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.7 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.6/1.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.7/1.7 MB 2.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.9/1.7 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.0/1.7 MB 2.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.2/1.7 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.2/1.7 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.3/1.7 MB 2.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.5/1.7 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.5/1.7 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.6/1.7 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 2.2 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Downloading streamlit-1.22.0-py2.py3-none-any.whl (8.9 MB)\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/8.9 MB 2.6 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.2/8.9 MB 2.3 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.3/8.9 MB 2.5 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.5/8.9 MB 2.5 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.6/8.9 MB 2.3 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.7/8.9 MB 2.4 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.8/8.9 MB 2.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.9/8.9 MB 2.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.0/8.9 MB 2.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.2/8.9 MB 2.3 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.2/8.9 MB 2.2 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.3/8.9 MB 2.1 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.4/8.9 MB 2.1 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.4/8.9 MB 2.0 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.5/8.9 MB 2.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.6/8.9 MB 2.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.6/8.9 MB 2.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.7/8.9 MB 2.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.8/8.9 MB 1.9 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.9/8.9 MB 1.9 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.9/8.9 MB 1.9 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.0/8.9 MB 1.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.0/8.9 MB 1.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.1/8.9 MB 1.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.2/8.9 MB 1.8 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.3/8.9 MB 1.8 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.4/8.9 MB 1.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 2.5/8.9 MB 1.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 2.6/8.9 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.7/8.9 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.7/8.9 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.8/8.9 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.0/8.9 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.1/8.9 MB 1.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.2/8.9 MB 1.8 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 3.4/8.9 MB 1.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 3.4/8.9 MB 1.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 3.5/8.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.6/8.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.7/8.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.7/8.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 3.9/8.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.0/8.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.1/8.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 4.2/8.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 4.3/8.9 MB 1.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.5/8.9 MB 1.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.6/8.9 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 4.7/8.9 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 4.8/8.9 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 4.8/8.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.0/8.9 MB 2.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 5.1/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.3/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.4/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.5/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.5/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.6/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.7/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.7/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 5.9/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.0/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.0/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.1/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.2/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 6.4/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.4/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.5/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.6/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 6.7/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 6.8/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 6.9/8.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.0/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.1/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.2/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.3/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.4/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.5/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.6/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.7/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.9/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.9/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.0/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.1/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.2/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.3/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.3/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.5/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.6/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.7/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.8/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.9/8.9 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.9/8.9 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading unstructured-0.9.2-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.4 MB 2.0 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.2/1.4 MB 2.1 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.2/1.4 MB 1.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.3/1.4 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.4/1.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.4 MB 1.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.6/1.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.7/1.4 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.7/1.4 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.8/1.4 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.9/1.4 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.4 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.0/1.4 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.1/1.4 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.3/1.4 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.4/1.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.4/1.4 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 1.7 MB/s eta 0:00:00\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_magic_bin-0.4.14-py2.py3-none-win_amd64.whl (409 kB)\n",
      "   ---------------------------------------- 0.0/409.3 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 61.4/409.3 kB 1.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 92.2/409.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 184.3/409.3 kB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 307.2/409.3 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 409.3/409.3 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.5/76.5 kB 4.4 MB/s eta 0:00:00\n",
      "Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "   ---------------------------------------- 0.0/813.6 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 112.6/813.6 kB 3.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 276.5/813.6 kB 3.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 399.4/813.6 kB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 542.7/813.6 kB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 696.3/813.6 kB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 813.6/813.6 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
      "Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.5/56.5 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "   ---------------------------------------- 0.0/162.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 162.1/162.1 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "   ---------------------------------------- 0.0/164.8 kB ? eta -:--:--\n",
      "   ---------------------------------------  163.8/164.8 kB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 164.8/164.8 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.5 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 112.6/268.5 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  266.2/268.5 kB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 268.5/268.5 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "   ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 92.2/199.4 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 199.4/199.4 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 3.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.3/1.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.5 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.5/1.5 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.6/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.8/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.9/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.1/1.5 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.2/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.4/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.5/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 1.5 MB/s eta 0:00:00\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Building wheels for collected packages: tiktoken, faiss-cpu, libmagic\n",
      "  Building wheel for tiktoken (pyproject.toml): started\n",
      "  Building wheel for tiktoken (pyproject.toml): finished with status 'error'\n",
      "  Building wheel for faiss-cpu (pyproject.toml): started\n",
      "  Building wheel for faiss-cpu (pyproject.toml): finished with status 'error'\n",
      "  Building wheel for libmagic (pyproject.toml): started\n",
      "  Building wheel for libmagic (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for libmagic: filename=libmagic-1.0-py3-none-any.whl size=4281 sha256=bdfab9cab18142f6625bfb787c1ee280bc7addc5735a018fffb7e8c79d754b6a\n",
      "  Stored in directory: c:\\users\\ankan mazumdar\\appdata\\local\\pip\\cache\\wheels\\ba\\32\\b5\\da21074580720b7a55fbf1a7597e3b1a325d12940ea6bd661b\n",
      "Successfully built libmagic\n",
      "Failed to build tiktoken faiss-cpu\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for tiktoken (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [37 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib.win-amd64-cpython-312\n",
      "      creating build\\lib.win-amd64-cpython-312\\tiktoken\n",
      "      copying tiktoken\\core.py -> build\\lib.win-amd64-cpython-312\\tiktoken\n",
      "      copying tiktoken\\load.py -> build\\lib.win-amd64-cpython-312\\tiktoken\n",
      "      copying tiktoken\\model.py -> build\\lib.win-amd64-cpython-312\\tiktoken\n",
      "      copying tiktoken\\registry.py -> build\\lib.win-amd64-cpython-312\\tiktoken\n",
      "      copying tiktoken\\__init__.py -> build\\lib.win-amd64-cpython-312\\tiktoken\n",
      "      creating build\\lib.win-amd64-cpython-312\\tiktoken_ext\n",
      "      copying tiktoken_ext\\openai_public.py -> build\\lib.win-amd64-cpython-312\\tiktoken_ext\n",
      "      running egg_info\n",
      "      writing tiktoken.egg-info\\PKG-INFO\n",
      "      writing dependency_links to tiktoken.egg-info\\dependency_links.txt\n",
      "      writing requirements to tiktoken.egg-info\\requires.txt\n",
      "      writing top-level names to tiktoken.egg-info\\top_level.txt\n",
      "      reading manifest file 'tiktoken.egg-info\\SOURCES.txt'\n",
      "      reading manifest template 'MANIFEST.in'\n",
      "      warning: no files found matching 'Makefile'\n",
      "      adding license file 'LICENSE'\n",
      "      writing manifest file 'tiktoken.egg-info\\SOURCES.txt'\n",
      "      copying tiktoken\\py.typed -> build\\lib.win-amd64-cpython-312\\tiktoken\n",
      "      running build_ext\n",
      "      running build_rust\n",
      "      error: can't find Rust compiler\n",
      "      \n",
      "      If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "      \n",
      "      To update pip, run:\n",
      "      \n",
      "          pip install --upgrade pip\n",
      "      \n",
      "      and then retry package installation.\n",
      "      \n",
      "      If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tiktoken\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for faiss-cpu (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [8 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      running build_ext\n",
      "      building 'faiss._swigfaiss' extension\n",
      "      swigging faiss\\faiss\\python\\swigfaiss.i to faiss\\faiss\\python\\swigfaiss_wrap.cpp\n",
      "      swig.exe -python -c++ -Doverride= -I/usr/local/include -Ifaiss -doxygen -DSWIGWIN -module swigfaiss -o faiss\\faiss\\python\\swigfaiss_wrap.cpp faiss\\faiss\\python\\swigfaiss.i\n",
      "      error: command 'swig.exe' failed: None\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for faiss-cpu\n",
      "ERROR: Could not build wheels for tiktoken, faiss-cpu, which is required to install pyproject.toml-based projects\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e1fbf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "#installing necessary libraries, libmagic is used for file type detection\n",
    "!pip3 install unstructured libmagic python-magic python-magic-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfca934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce75de",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredURLLoader(\n",
    "    urls = [\n",
    "        \"https://www.moneycontrol.com/news/business/banks/hdfc-bank-re-appoints-sanmoy-chakrabarti-as-chief-risk-officer-11259771.html\",\n",
    "        \"https://www.moneycontrol.com/news/business/markets/market-corrects-post-rbi-ups-inflation-forecast-icrr-bet-on-these-top-10-rate-sensitive-stocks-ideas-11142611.html\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be914bfa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52838711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movie_id: 101\\ntitle: K.G.F: Chapter 2\\nindustry: Bollywood\\nrelease_year: 2022\\nimdb_rating: 8.4\\nstudio'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].page_content[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b587350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'K.G.F: Chapter 2', 'row': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df45adf4",
   "metadata": {},
   "source": [
    "## Text Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce2e736",
   "metadata": {},
   "source": [
    "Why do we need text splitters in first place?\n",
    "\n",
    "LLM's have token limits. Hence we need to split the text which can be large into small chunks so that each chunk size is under the token limit. There are various text splitter classes in langchain that allows us to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90431c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking some random text from wikipedia\n",
    "\n",
    "text = \"\"\"Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan. \n",
    "It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine. \n",
    "Set in a dystopian future where humanity is embroiled in a catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for humankind.\n",
    "\n",
    "Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007 and was originally set to be directed by Steven Spielberg. \n",
    "Kip Thorne, a Caltech theoretical physicist and 2017 Nobel laureate in Physics,[4] was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar. \n",
    "Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm. Principal photography began in late 2013 and took place in Alberta, Iceland, and Los Angeles. \n",
    "Interstellar uses extensive practical and miniature effects, and the company Double Negative created additional digital effects.\n",
    "\n",
    "Interstellar premiered in Los Angeles on October 26, 2014. In the United States, it was first released on film stock, expanding to venues using digital projectors. The film received generally positive reviews from critics and grossed over $677 million worldwide ($715 million after subsequent re-releases), making it the tenth-highest-grossing film of 2014. \n",
    "It has been praised by astronomers for its scientific accuracy and portrayal of theoretical astrophysics.[5][6][7] Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects, and received numerous other accolades.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af9a95b",
   "metadata": {},
   "source": [
    "#### Manual approach of splitting the text into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a51fc70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher N'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Say LLM token limit is 100, in that case we can do simple thing such as this\n",
    "\n",
    "text[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2adae99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Well but we want complete words and want to do this for entire text, may be we can use Python's split funciton\n",
    "\n",
    "words = text.split(\" \")\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56ec5613",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "\n",
    "s = \"\"\n",
    "for word in words:\n",
    "    s += word + \" \"\n",
    "    if len(s)>200:\n",
    "        chunks.append(s)\n",
    "        s = \"\"\n",
    "        \n",
    "chunks.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95d902bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan. \\nIt stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt ',\n",
       " 'Damon, and Michael Caine. \\nSet in a dystopian future where humanity is embroiled in a catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in ']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Obtaining dependency information for unstructured from https://files.pythonhosted.org/packages/05/52/941f0caff2cec92340946aa7245bebf8546e1117bfc4085eaf7616a16544/unstructured-0.14.2-py3-none-any.whl.metadata\n",
      "  Downloading unstructured-0.14.2-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting libmagic\n",
      "  Using cached libmagic-1.0-py3-none-any.whl\n",
      "Collecting python-magic\n",
      "  Obtaining dependency information for python-magic from https://files.pythonhosted.org/packages/6c/73/9f872cb81fc5c3bb48f7227872c28975f998f3e7c2b1c16e95e6432bbb90/python_magic-0.4.27-py2.py3-none-any.whl.metadata\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting python-magic-bin\n",
      "  Obtaining dependency information for python-magic-bin from https://files.pythonhosted.org/packages/07/c2/094e3d62b906d952537196603a23aec4bcd7c6126bf80eb14e6f9f4be3a2/python_magic_bin-0.4.14-py2.py3-none-win_amd64.whl.metadata\n",
      "  Using cached python_magic_bin-0.4.14-py2.py3-none-win_amd64.whl.metadata (710 bytes)\n",
      "Collecting chardet (from unstructured)\n",
      "  Obtaining dependency information for chardet from https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl.metadata\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured)\n",
      "  Obtaining dependency information for filetype from https://files.pythonhosted.org/packages/18/79/1b8fa1bb3568781e84c9200f951c735f3f157429f44be0495da55894d620/filetype-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: lxml in c:\\python\\lib\\site-packages (from unstructured) (4.9.3)\n",
      "Collecting nltk (from unstructured)\n",
      "  Obtaining dependency information for nltk from https://files.pythonhosted.org/packages/a6/0a/0d20d2c0f16be91b9fa32a77b76c60f9baf6eba419e5ef5deca17af9c582/nltk-3.8.1-py3-none-any.whl.metadata\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting tabulate (from unstructured)\n",
      "  Obtaining dependency information for tabulate from https://files.pythonhosted.org/packages/40/44/4a5f08c96eb108af5cb50b41f76142f0afa346dfa99d5296fe7202a11854/tabulate-0.9.0-py3-none-any.whl.metadata\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: requests in c:\\python\\lib\\site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\python\\lib\\site-packages (from unstructured) (4.12.3)\n",
      "Collecting emoji (from unstructured)\n",
      "  Obtaining dependency information for emoji from https://files.pythonhosted.org/packages/e6/90/20ad30babfa8f2b5ab46281d8e17bdfdbb3ac294cda14d525b9c2d958846/emoji-2.12.1-py3-none-any.whl.metadata\n",
      "  Downloading emoji-2.12.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: dataclasses-json in c:\\python\\lib\\site-packages (from unstructured) (0.6.6)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Obtaining dependency information for python-iso639 from https://files.pythonhosted.org/packages/01/08/5e649cf18dec750d498c53c6c8eb1d9790752ebd50fa7f7e69cc0c277cfe/python_iso639-2024.4.27-py3-none-any.whl.metadata\n",
      "  Downloading python_iso639-2024.4.27-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     - ----------------------------------- 41.0/981.5 kB 960.0 kB/s eta 0:00:01\n",
      "     --- ----------------------------------- 92.2/981.5 kB 1.3 MB/s eta 0:00:01\n",
      "     ------ ------------------------------- 174.1/981.5 kB 1.3 MB/s eta 0:00:01\n",
      "     --------- ---------------------------- 245.8/981.5 kB 1.4 MB/s eta 0:00:01\n",
      "     ------------ ------------------------- 327.7/981.5 kB 1.4 MB/s eta 0:00:01\n",
      "     --------------- ---------------------- 399.4/981.5 kB 1.4 MB/s eta 0:00:01\n",
      "     ----------------- -------------------- 450.6/981.5 kB 1.3 MB/s eta 0:00:01\n",
      "     ------------------ ------------------- 481.3/981.5 kB 1.3 MB/s eta 0:00:01\n",
      "     --------------------- ---------------- 542.7/981.5 kB 1.3 MB/s eta 0:00:01\n",
      "     ------------------------ ------------- 624.6/981.5 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------- ----------- 696.3/981.5 kB 1.4 MB/s eta 0:00:01\n",
      "     ------------------------------ ------- 788.5/981.5 kB 1.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ---- 860.2/981.5 kB 1.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- -- 921.6/981.5 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------  972.8/981.5 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------  972.8/981.5 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 981.5/981.5 kB 1.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\python\\lib\\site-packages (from unstructured) (1.26.2)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Obtaining dependency information for rapidfuzz from https://files.pythonhosted.org/packages/56/2f/2b5bba74bc58d9ed18266450618fed68bbb3206245d5cfd39681cfc7b813/rapidfuzz-3.9.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading rapidfuzz-3.9.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Obtaining dependency information for backoff from https://files.pythonhosted.org/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl.metadata\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\python\\lib\\site-packages (from unstructured) (4.8.0)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Obtaining dependency information for unstructured-client from https://files.pythonhosted.org/packages/b0/bc/c74937363c2657a77e4c4e105b7a004203ad53f128b5caf5dbb9dc9458d1/unstructured_client-0.22.0-py3-none-any.whl.metadata\n",
      "  Downloading unstructured_client-0.22.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting wrapt (from unstructured)\n",
      "  Obtaining dependency information for wrapt from https://files.pythonhosted.org/packages/5c/cc/8297f9658506b224aa4bd71906447dea6bb0ba629861a758c28f67428b91/wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python\\lib\\site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\python\\lib\\site-packages (from dataclasses-json->unstructured) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\python\\lib\\site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\ankan mazumdar\\appdata\\roaming\\python\\python312\\site-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\python\\lib\\site-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\python\\lib\\site-packages (from nltk->unstructured) (1.3.2)\n",
      "Collecting regex>=2021.8.3 (from nltk->unstructured)\n",
      "  Obtaining dependency information for regex>=2021.8.3 from https://files.pythonhosted.org/packages/8b/ee/05f14a99a81f1a897a9146f3f565efb116ad6412f875f52e895c02666825/regex-2024.5.15-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached regex-2024.5.15-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in c:\\python\\lib\\site-packages (from nltk->unstructured) (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\lib\\site-packages (from requests->unstructured) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\lib\\site-packages (from requests->unstructured) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\lib\\site-packages (from requests->unstructured) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\lib\\site-packages (from requests->unstructured) (2023.7.22)\n",
      "Collecting deepdiff>=6.0 (from unstructured-client->unstructured)\n",
      "  Obtaining dependency information for deepdiff>=6.0 from https://files.pythonhosted.org/packages/18/e6/d27d37dc55dbf40cdbd665aa52844b065ac760c9a02a02265f97ea7a4256/deepdiff-7.0.1-py3-none-any.whl.metadata\n",
      "  Downloading deepdiff-7.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured)\n",
      "  Obtaining dependency information for jsonpath-python>=1.0.6 from https://files.pythonhosted.org/packages/16/8a/d63959f4eff03893a00e6e63592e3a9f15b9266ed8e0275ab77f8c7dbc94/jsonpath_python-1.0.6-py3-none-any.whl.metadata\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in c:\\python\\lib\\site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: packaging>=23.1 in c:\\users\\ankan mazumdar\\appdata\\roaming\\python\\python312\\site-packages (from unstructured-client->unstructured) (23.2)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
      "  Obtaining dependency information for pypdf>=4.0 from https://files.pythonhosted.org/packages/c9/d1/450b19bbdbb2c802f554312c62ce2a2c0d8744fe14735bc70ad2803578c7/pypdf-4.2.0-py3-none-any.whl.metadata\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ankan mazumdar\\appdata\\roaming\\python\\python312\\site-packages (from unstructured-client->unstructured) (2.8.2)\n",
      "Collecting ordered-set<4.2.0,>=4.1.0 (from deepdiff>=6.0->unstructured-client->unstructured)\n",
      "  Obtaining dependency information for ordered-set<4.2.0,>=4.1.0 from https://files.pythonhosted.org/packages/33/55/af02708f230eb77084a299d7b08175cff006dea4f2721074b92cdb0296c0/ordered_set-4.1.0-py3-none-any.whl.metadata\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\ankan mazumdar\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk->unstructured) (0.4.6)\n",
      "Downloading unstructured-0.14.2-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/2.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 2.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.4/2.0 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.6/2.0 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.7/2.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.8/2.0 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.0 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/2.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/2.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/2.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.3/2.0 MB 2.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.4/2.0 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.4/2.0 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.5/2.0 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/2.0 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.7/2.0 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/2.0 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.9/2.0 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 2.0 MB/s eta 0:00:00\n",
      "Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Using cached python_magic_bin-0.4.14-py2.py3-none-win_amd64.whl (409 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
      "   ---------------------------------------- 0.0/431.4 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 81.9/431.4 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 112.6/431.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 266.2/431.4 kB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 327.7/431.4 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 431.4/431.4 kB 2.1 MB/s eta 0:00:00\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading python_iso639-2024.4.27-py3-none-any.whl (274 kB)\n",
      "   ---------------------------------------- 0.0/274.7 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 174.1/274.7 kB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 266.2/274.7 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 274.7/274.7 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading rapidfuzz-3.9.1-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.1/1.6 MB 7.7 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.3/1.6 MB 3.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.4/1.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.6/1.6 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.7/1.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.8/1.6 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.0/1.6 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.1/1.6 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.1/1.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.2/1.6 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.3/1.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.4/1.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.5/1.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.6/1.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 2.4 MB/s eta 0:00:00\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading unstructured_client-0.22.0-py3-none-any.whl (28 kB)\n",
      "Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Downloading deepdiff-7.0.1-py3-none-any.whl (80 kB)\n",
      "   ---------------------------------------- 0.0/80.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 80.8/80.8 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "   ---------------------------------------- 0.0/290.4 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 112.6/290.4 kB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 235.5/290.4 kB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 290.4/290.4 kB 2.2 MB/s eta 0:00:00\n",
      "Using cached regex-2024.5.15-cp312-cp312-win_amd64.whl (268 kB)\n",
      "Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (pyproject.toml): started\n",
      "  Building wheel for langdetect (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993255 sha256=cf8810bac3214f7ab8778c6adb9684edbc1472609b2970c182b359e517d1e120\n",
      "  Stored in directory: c:\\users\\ankan mazumdar\\appdata\\local\\pip\\cache\\wheels\\c1\\67\\88\\e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "Successfully built langdetect\n",
      "Installing collected packages: python-magic-bin, libmagic, filetype, wrapt, tabulate, regex, rapidfuzz, python-magic, python-iso639, pypdf, ordered-set, langdetect, jsonpath-python, emoji, chardet, backoff, nltk, deepdiff, unstructured-client, unstructured\n",
      "Successfully installed backoff-2.2.1 chardet-5.2.0 deepdiff-7.0.1 emoji-2.12.1 filetype-1.2.0 jsonpath-python-1.0.6 langdetect-1.0.9 libmagic-1.0 nltk-3.8.1 ordered-set-4.1.0 pypdf-4.2.0 python-iso639-2024.4.27 python-magic-0.4.27 python-magic-bin-0.4.14 rapidfuzz-3.9.1 regex-2024.5.15 tabulate-0.9.0 unstructured-0.14.2 unstructured-client-0.22.0 wrapt-1.16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "chunks[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff06ebc4",
   "metadata": {},
   "source": [
    "**Splitting data into chunks can be done in native python but it is a tidious process. Also if necessary, you may need to experiment with various delimiters in an iterative manner to ensure that each chunk does not exceed the token length limit of the respective LLM.**\n",
    "\n",
    "**Langchain provides a better way through text splitter classes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64b2909",
   "metadata": {},
   "source": [
    "#### Using Text Splitter Classes from Langchain\n",
    "\n",
    "#### CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9505bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d86bc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 210, which is longer than the specified 200\n",
      "Created a chunk of size 208, which is longer than the specified 200\n",
      "Created a chunk of size 358, which is longer than the specified 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = splitter.split_text(text)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e027b9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "120\n",
      "210\n",
      "181\n",
      "197\n",
      "207\n",
      "128\n",
      "357\n",
      "253\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    print(len(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc73da3",
   "metadata": {},
   "source": [
    "As you can see, all though we gave 200 as a chunk size since the split was based on \\n, it ended up creating chunks that are bigger than size 200. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86f3a10",
   "metadata": {},
   "source": [
    "Another class from Langchain can be used to recursively split the text based on a list of separators. This class is RecursiveTextSplitter. Let's see how it works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a61cf1",
   "metadata": {},
   "source": [
    "#### RecursiveTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dacf5e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan. \\nIt stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine. \\nSet in a dystopian future where humanity is embroiled in a catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for humankind.\\n\\nBrothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007 and was originally set to be directed by Steven Spielberg. \\nKip Thorne, a Caltech theoretical physicist and 2017 Nobel laureate in Physics,[4] was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar. \\nCinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm. Principal photography began in late 2013 and took place in Alberta, Iceland, and Los Angeles. \\nInterstellar uses extensive practical and miniature effects, and the company Double Negative created additional digital effects.\\n\\nInterstellar premiered in Los Angeles on October 26, 2014. In the United States, it was first released on film stock, expanding to venues using digital projectors. The film received generally positive reviews from critics and grossed over $677 million worldwide ($715 million after subsequent re-releases), making it the tenth-highest-grossing film of 2014. \\nIt has been praised by astronomers for its scientific accuracy and portrayal of theoretical astrophysics.[5][6][7] Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects, and received numerous other accolades.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "848eae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators = [\"\\n\\n\", \"\\n\", \" \"],  # List of separators based on requirement (defaults to [\"\\n\\n\", \"\\n\", \" \"])\n",
    "    chunk_size = 200,  # size of each chunk created\n",
    "    chunk_overlap  = 0,  # size of  overlap between chunks in order to maintain the context\n",
    "    length_function = len  # Function to calculate size, currently we are using \"len\" which denotes length of string however you can pass any token counter)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1151c51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "120\n",
      "199\n",
      "10\n",
      "181\n",
      "197\n",
      "198\n",
      "8\n",
      "128\n",
      "191\n",
      "165\n",
      "198\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "chunks = r_splitter.split_text(text)\n",
    "\n",
    "for chunk in chunks:\n",
    "    print(len(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32135f4d",
   "metadata": {},
   "source": [
    "**Let's understand how exactly it formed these chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57ef6974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan. \\nIt stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine. \\nSet in a dystopian future where humanity is embroiled in a catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for humankind.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_split = text.split(\"\\n\\n\")[0]\n",
    "first_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bc7719f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "439"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1018d24",
   "metadata": {},
   "source": [
    "Recursive text splitter uses a list of separators, i.e.  separators = [\"\\n\\n\", \"\\n\", \".\"]\n",
    "\n",
    "So now it will first split using \\n\\n and then if the resulting chunk size is greater than the chunk_size parameter which is 200\n",
    "in our case, then it will use the next separator which is \\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "739cef71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan. ',\n",
       " 'It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine. ',\n",
       " 'Set in a dystopian future where humanity is embroiled in a catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for humankind.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_split = first_split.split(\"\\n\")\n",
    "second_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "903f5921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "121\n",
      "210\n"
     ]
    }
   ],
   "source": [
    "for split in second_split:\n",
    "    print(len(split))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1e69a7",
   "metadata": {},
   "source": [
    "Third split exceeds chunk size 200. Now it will further try to split that using the third separator which is ' ' (space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69f4da9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Set in a dystopian future where humanity is embroiled in a catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for humankind.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_split[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fda659a",
   "metadata": {},
   "source": [
    "When you split this using space (i.e. second_split[2].split(\" \")), it will separate out each word and then it will merge those \n",
    "chunks such that their size is close to 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f538e50",
   "metadata": {},
   "source": [
    "<img src=\"chunk_size.jpg\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
